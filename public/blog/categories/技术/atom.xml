<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类: 技术 | Hegel2011的博客]]></title>
  <link href="http://octopresszhangyu.herokuapp.com/blog/categories/技术/atom.xml" rel="self"/>
  <link href="http://octopresszhangyu.herokuapp.com/"/>
  <updated>2023-09-08T19:24:28+08:00</updated>
  <id>http://octopresszhangyu.herokuapp.com/</id>
  <author>
    <name><![CDATA[Hegel 2011]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Kubernetes Book]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2021/10/26/the-kubernetes-book/"/>
    <updated>2021-10-26T09:47:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2021/10/26/the-kubernetes-book</id>
    <content type="html"><![CDATA[<p>The Kubernetes book, 购于Leanpub</p>

<h1>1&amp;2 Kubernetes 基础和操作</h1>

<h2>Control plane node (Masters, Heads)</h2>

<p>The API Server<br/>
   所有的入口</p>

<p>The cluster store(etcd)<br/>
    分布式数据库，3-5个拷贝，采用RAFT算法，由一个领袖说了算
    C优先于A，一旦不一致，就不能再更新了</p>

<p>The Controller manager<br/>
    Deployment, StatefulSet, ReplicaSet</p>

<p>The Scheduler<br/>
    检查Node的状况，给Node评分，以挑选合适的可以执行任务的Node</p>

<p>The cloud controller manager<br/>
    提供公有云服务的load-balancer到app的连接等</p>

<h2>Worker(Kubelet)</h2>

<p>Kubelet<br/>
    安装在主机上的代理，负责向heads汇报状态，并接受任务安排</p>

<p>Containerd<br/>
    从Docker抽象出来的接口，K8S已经不再直接支持Docker</p>

<p>kube-proxy<br/>
    运行在node上的网络组件，给每个node分配不同的docker内网，建立iptables表格完成路由功能</p>

<p>Kubernetes DNS<br/>
    每个Pod都有一个静态的Ip地址写了DNS服务，基于开源CoreDNS项目开发</p>

<h2>声明模式和渴望的状态</h2>

<ol>
<li>在manifest文件里声明目标状态（image，replicas数量，网络端口，如何更新）</li>
<li>Post给API服务（kubectl命令）</li>
<li>Kubernetes存入集群store（解析并分解成操作步骤入库）</li>
<li>Kubernetes实现目标状态(安排任务执行)</li>
<li>一个controller确保观察到的状态不会和目标状态不同(reconcile循环)</li>
</ol>


<h2>Pods</h2>

<p>A flock of birds 一群鸟 A pod of whales 一群鲸<br/>
所以pod就是一群dockers/containers</p>

<h2>Deployments</h2>

<p>一般不会直接部署pods，而是通过Controllers进行部署</p>

<h2>Service</h2>

<p>提供TCP UDP层面稳定的网络抽象</p>

<h1>3. 部署Kubernetes</h1>

<p>AWS: EKS, Azure: AKS, Google: GKE<br/>
腾讯: TKE, 阿里云: ACS（C是container）的缩写</p>

<p>可以在自己的机器上部署K8S作为练习：如docker Desktop，k3d, 开发可以用单机版的尝试</p>

<h2>kubectl</h2>

<p>~/.kube/config，中存放了命令行的操作配置</p>

<p>Clusters，Users和Contexts，前二者可以通过最后一个进行关联，表示用哪个用户的账号去操作哪个cluster</p>

<p><code>kubectl config current-context</code>用于查看当前活跃的context<br/>
<code>kubectl config use-context docker2</code> 用于调整当前活跃的context</p>

<h1>4. 用Pods工作</h1>

<ol>
<li>让资源共享：文件系统、同一个IP、共享内存、共享存储</li>
<li>一个pod中可以有多个containers，同一pod内的container可以通过localhost+不同的端口进行通信</li>
<li>通过Controller部署的pods才有高可用等特性支持</li>
<li>直接通过Pod manifest部署的pod，只有自生自灭</li>
</ol>


<p>Pod本身就是容器</p>

<h2>The pod network</h2>

<p>Pod的网络叫做pod network，是一种扁平的、各个pod可以彼此直接访问的组网。</p>

<h2>生命周期有长有短的pod</h2>

<p>long-lived: Deployments, StatefulSets, DaemonSets<br/>
short-lived: CronJobs, Jobs</p>

<p>长的多用于服务，短的多用于批量job。</p>

<h2>多Containers的几种花样</h2>

<p>Sidecar: 德国摩托车旁边的侧车；即一个container为主，一个为辅的模式。serice mesh里面常常用来对流量加密、暴露测量的数据<br/>
Adapter: sidecar的变种，比如把nginx的日志转变成普罗米修斯能解析的格式<br/>
Ambassador：也是变种，含义上讲更像是主container的使者<br/>
Init: 在拉起主app之前，执行一些辅助工作，通常只执行一次</p>

<p><code>kubectl apply -f pod.yml</code> 运行一个简单的pod，下面两个命令用于查询pod及其内容器的状态<br/>
<code>kubectl describe pods hello-pod</code><br/>
<code>kubectl get pods  hello-pod  -o wide</code></p>

<p>普通的执行命令 <code>kubectl exec hello-pod -- ps aux</code><br/>
获取pod内shell的命令 <code>kubectl exec -it hello-pod -- sh</code>, 注意需要加上<code>it</code></p>

<h1>5. Namespace</h1>

<p>查看命名空间 <code>kubectl get namespaces</code>  可以缩写为<code>ns</code></p>

<p>用kubectl可以命令式创建ns，用yaml文档可以声明式创建<br/>
<code>kubectl create ns hydra</code><br/>
<code>kubectl apply -f shields-ns.yml</code></p>

<p>切换默认的ns <code>kubectl config set-context --current --namespace ss</code></p>

<p>声明式的清除 <code>kubectl delete -f shield-app.yml</code></p>

<h1>6. Kubernetes部署</h1>

<p>Workload apis: Deployments, DaemonSets, StatefulSets</p>

<p>Deployments是aggregation root，内部其实还有ReplicaSet， 通过ReplicaSet来操作Pods</p>

<p>Reconcile：补锅，补偿，使得现实变成目标</p>

<pre><code class="yaml">piVersion: apps/v1
kind: Deployment
metadata:
  name: hello-deploy
spec:
  replicas: 10
  selector:
    matchLabels:
      app: hello-world
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    metadata:
      labels:
        app: hello-world
    spec:
      containers:
      - name: hello-pod
        image: nigelpoulton/k8sbook:latest
        ports:
        - containerPort: 8080
</code></pre>

<p><code>.spec.selector</code>中的label选择了template中的app，注意label Selectors</p>

<p><code>ubectl get deploy hello-deploy</code><br/>
<code>kubectl scale deploy hello-deploy --replicas 5</code></p>

<p>rollback， clean-up</p>

<h1>7. Service</h1>

<ol>
<li>Service是一个K8S对象</li>
<li>Service有稳定的ip地址(a cluster ip)、dns名字以及port口</li>
<li>利用labels和selectors去动态地选择pods以传递流量</li>
</ol>


<p>从外部访问的方法：1. NodePort， 2. LoadBalancer</p>

<p>使用DNS服务作为服务发现的核心。Service名称会自动注册到DNS集群中，每个pod及其container都预先配置了dns集群的配置，以解决Service Name 到 ClusterIP之间的映射</p>

<h1>8. Ingress</h1>

<p>Ingress属于七层交换的概念，可以通过域名或路径等组合来转发请求</p>

<p>NodePorts的缺点： 使用的port偏大，30000-32767<br/>
LoadBalancer缺点： 需要和云的load-balancer 1-to-1 对应，开销容易很大<br/>
Ingress可以在只有一个云load-balancer的情况下完成多个服务的路由</p>

<p>不过，如果使用一个service mesh，可能Ingress的作用就不大了。</p>

<p>Ingress也是一种controller，只是大部分不是内建的。</p>

<p>可以使用helm创建nginx-ingress</p>

<pre><code>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update
helm install ingress-nginx ingress-nginx/ingress-nginx --namespace ss
kubectl get pods -n ss -o wide

ingress-nginx-controller-5c8d66c76d-2kq2f   1/1     Running   0          49m   10.244.2.34   master-node   &lt;none&gt;           &lt;none&gt;

kubectl get svc
NAME                                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
ingress-nginx-controller             LoadBalancer   10.108.112.4    &lt;pending&gt;     80:32003/TCP,443:30330/TCP   50m
</code></pre>

<p>但因为是自建的kubeadm，所以没有云原生的直接load-balance的支持，但可以通过32003端口对服务进行访问。</p>

<h1>9. 服务发现详解</h1>

<pre><code>kubectl get pods -n kube-system  -o wide
NAME                                           READY   STATUS    RESTARTS      AGE   IP             NODE                   NOMINATED NODE   READINESS GATES
coredns-78fcd69978-kb5td                       1/1     Running   1 (8d ago)    59d   10.244.0.4     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
coredns-78fcd69978-l6m5g                       1/1     Running   1 (8d ago)    59d   10.244.0.5     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
</code></pre>

<p>control plane上有dns集群</p>

<p>svc部署后会分配一个vip，也就是clusterIp；因为svc name最终会进入dns服务，所以这也是svc的命名规则要求和dns域名一致的根本原因</p>

<p>Kube-proxy会完成对Endpoints的监控和转发调整。现代版本的linux普遍使用IPVS，老的使用iptables。</p>

<p>clusterIp是一个不存在的IP，所以container传给node，node传给它的gateway（node的kernel，IPVS或Iptables），由kube-proxy负责对ClusterIp的重定向。
IPVS是L4 load-balancer，扩展的性能更优越。</p>

<p>服务发现和namespace</p>

<p><code>&lt;object-name&gt;.&lt;namespace&gt;.svc.cluster.local</code></p>

<p><code>kubectl get all -n dev</code> 可以同时列出 svc pods</p>

<h1>10. Storage</h1>

<p>Storage采用的CSI plugin的机制。</p>

<p>SC - StorageClass 定义存储的硬件<br/>
PVC - 变成PV的请求，也是Pod可以使用的存储  <br/>
PV - SC检测到PVC后，会变成PV</p>

<ul>
<li>PVC里的Access mode:

<ul>
<li>ReadWriteOnce(RWO)传统的一块硬盘</li>
<li>ReadWriteMany(RWM) NFS这种支持多个加载</li>
<li>ReadOnlyMany(ROM)  可被多少只读</li>
</ul>
</li>
</ul>


<p>PV只能按一种模式打开</p>

<p><code>kubectl get sc</code></p>

<p>解除后数据是否删除的策略：1. Delete 2. Retain<br/>
Sc中的VolumeBindingModo: 1. Immediate 2. WaitingForFirstConsumer(Pod)</p>

<pre><code class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: volpod
spec:
  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: pvc-prem
  containers:
  - name: ubuntu-ctr
    image: ubuntu:latest
    command:
    - /bin/bash
    - "-c"
    - "sleep 60m"
    volumeMounts:
    - mountPath: /data
      name: data
</code></pre>

<h1>11. ConfigMaps and Secrets</h1>

<p>ConfigMaps是键值对，value可以是一个简单的值，也可以是一整个配置文件。<br/>
注入container有几种方式：1. 环境变量 2. 启动的命令 3. volume中的文件<br/>
env var； cmd； vol</p>

<p><code>kubectl create configmap</code></p>

<p>vol最大的优势是一旦修改了configMap，可以在container的mount位置立刻看见修改。而两位两个必须重启容器。即Vol的注入是动态的，env的注入是静态的。</p>

<p>Secret只是以base64的形势存放起来</p>

<h1>12. StatefulSets</h1>

<p>与Deployment相比的差异：<br/>
1. 可预知的持久的pod名字<br/>
2. 可预知的持久的DNS主机名字<br/>
3. 可预知的持久度vol绑定</p>

<p>pod生成的规则：<StatefuleSetName>-<Integer>，而且是按顺序依次启动，完成前一个，才启动后一个。</p>

<p>Stateful controllers自己直接处理治愈和扩容，而不是假手ReplicaSet</p>

<h2>headless service and StatefulSet's governing service</h2>

<p>headless service就是clusterIP为空的service，搭配StatuefulSet，就会产生独立的每个pod的dns名称。app的调用也会基于具体的pod 名称。</p>

<p><code>volumeClaimTemplates</code>用于给每个stateful pod创建动态PVC。</p>

<p>独立pod的dns命名规则为<object-name>.<service-name>.<namespace>.svc.cluster.local</p>

<p>如果是pod退出，那么StatefulSet可以很容易地重新创建一个替代的pod。但如果是node不正常，则需要手工干预。</p>

<h1>13. API 安全和RBAC</h1>

<p>user,gourp, Service acct -> API server -> authN -> authZ -> Admission control</p>

<p>Kubernetes没有自己的identity database，主要通过和其他auth模块集成（plug-in）的方式来实现authN。<br/>
比如client certs，webhooks，IAM（Identity Access Management)</p>

<p>K8S的authZ只有allow没有deny，因为默认全部都是deny。</p>

<pre><code class="yaml">rules:
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["get", "watch", "list"]
</code></pre>

<p><code>*</code>意味着全部授权</p>

<p>4个RBAC对象</p>

<ul>
<li>Roles</li>
<li>ClusterRoles</li>
<li>RoleBindings</li>
<li>ClusterRoleBindings</li>
</ul>


<p>顾名思义，可以使用的namespace是不同的。需要注意的是，ClusterRoles经常和RoleBindings搭配使用。</p>

<p>Admission controller有很多个，实际主要负责批准相应的请求。</p>

<h1>14. The Kubernetes API</h1>

<p>JSON + Protobuf支持，</p>

<p>可以自己定义并扩展API</p>

<h1>15. Threat和K8S</h1>

<p>STRIDE 模型</p>

<p>Spoofing欺骗:<br/>
  - 通信层面的安全TLS<br/>
  - 限制pod和API server的通信，token的失效期等等</p>

<p>Tampering篡改:<br/>
  - 组件的篡改：etcd，api server，controller，scheduler，kubelet，镜像运行时，镜像文件等<br/>
  - 运行的pod修改</p>

<p>Repudiation否认:<br/>
  - 中央化的收集各个组件的审计日志</p>

<p>Information Disclosure 信息泄露:<br/>
  - KMS和HSM是实现key和数据在节点上分离</p>

<p>Denial of Service(DOS):<br/>
  - HA<br/>
  - WAF</p>

<p>Elevation of privilege:</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java 8 9 10 in action]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2021/10/04/java-8-9-10-in-action/"/>
    <updated>2021-10-04T21:22:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2021/10/04/java-8-9-10-in-action</id>
    <content type="html"><![CDATA[<h1>第一章</h1>

<p>第一作者写作时是剑桥的在读博士，同时第三作者是他的博士生导师。第二作者是Redhat的Java 8普及牛人。</p>

<p>Brian Goetz 把函数式编程内容加入Java，他也是java的架构师或者说设计师。</p>

<p>本书涉及了Stream, lambda, Optional, CompletableFuture, RxJava, Akka(Java 9)</p>

<p>Function变成一等公民，可以在运行时被传来传去。<br/>
method reference :: syntax<br/>
lambdas</p>

<p>原本<code>filter</code>等功能可以添加在Collections类中。但为了匹配多核时代，引入了streams，对并行(parallelStream)和单行stream进行了区分。</p>

<p><code>Default Method</code>的加入是为了让已经存在的List的实现类可以不需要自己单独去实现stream()这种方法，但这让java具备了多继承的能力。因为default method的加入，等于接口可以变成抽象类。</p>

<h1>第二章 行为参数化传递的方式</h1>

<p>lambda也是一个对象，也可以用工厂方法来构造</p>

<p>以前传行为（策略模式）是需要构造一系列的接口和类，实现共同的接口，因为只能传入对象。<br/>
Java匿名类：允许你声明和初始化一个类在同一时刻。<br/>
lambda和上面的特性一样，但更加精简</p>

<p>4个实际经常使用的匿名类接口：<code>Comparator</code>，<code>Runnable</code>，<code>Callable</code>，<code>EventHandler</code></p>

<h1>第三章 Lambda</h1>

<p>lambda可在Functional Interface(例如Predicate<T>）处被传入</p>

<p><strong>Functional Inteface就是有且只有一个抽象方法的接口。</strong><br/>
lambda就是一个Functional Interface的抽象方法的实现实例<br/>
<code>@FunctionalInterface</code> 对于Functional Interface的标注，表示有且仅有一个抽象接口。</p>

<p>FunctionalInterface就是lambda的引用类型，此时func也就变成了一个对象。<br/>
<code>java
Predicate&lt;T&gt; &lt;---&gt; T --&gt; boolean
Consumer&lt;T&gt; &lt;---&gt; T-&gt; void
Function&lt;T, R&gt; &lt;---&gt; T -&gt; R
Supplier&lt;T&gt; &lt;---&gt; () -&gt; T
Runnable &lt;---&gt; () -&gt; {}
</code></p>

<p>因为boxing的性能原因，上面还有一系列Int Long 之类的变种</p>

<h2>Target typing</h2>

<p>先根据被使用的FI类型，比如<code>filter</code>是<code>Predicate</code>，那么意味着需要一个输入为<code>T</code>返回为<code>boolean</code>的lambda。<br/>
同时，因为这个接口里面的method名字lambda并不会涉及，实际上叫什么也无所谓，所以要求FI只能有一个抽象method。这样的话，method具体叫什么就无所谓了，只要方法签名对的上，实现中甚至可以单独生成一个匿名类。</p>

<p>local variable 和instance variable在lambda中的异同，因为他们在JVM里面的位置不同，local var是在本地func的stack里，实例变量则在Heap中。所以local var必须加上final或者实际上只被赋值一次。</p>

<h2>3种Method Reference</h2>

<ol>
<li>静态方法 <code>Integer::parseInt</code></li>
<li>实例方法 <code>String::length</code></li>
<li>已存在对象的实例方法 <code>expensiveTransaction::insert</code></li>
</ol>


<p>上面的方法都可以传入多个参数，但同时也不需要使用()，毕竟只是声明需要使用这个method</p>

<p>构造方法作为一种特殊的method，也能成为method Reference</p>

<h2>FI中的其他接口（组合lambda表达式）</h2>

<p>适用组合模式，其他接口都是<code>default</code>类型的接口</p>

<p><code>Comparator: reversed, thenComparing</code><br/>
<code>Predicate: and, or, not</code>  <br/>
<code>Function: andThen, compose</code>, 注意二者的区别，前者是管道，后者是被compose的内容先执行</p>

<pre><code class="java">    Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;
    Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;
    Function&lt;Integer, Integer&gt; h = f.andThen(g);
    System.out.println("h(1): " + h.apply(1));
</code></pre>

<h1>第四章 Stream</h1>

<p><code>Collection</code>的弱点：1. 不能像SQL那样组合查询（declarative way 声明式查询） 2. 集合太大可能无法处理</p>

<p>民间自发的：<code>Guava</code>，<code>Apache</code>，<code>lambdaj</code>（本书第二作者的作品）</p>

<p><strong>Stream</strong>: Declarative, Composable, Parallelizable</p>

<p>Compute on demand, a lazily constructed collection</p>

<p>中间的操作：<code>filter</code>，<code>map</code>，<code>limit</code>， <code>sorted</code>，<code>distinct</code><br/>
Terminal操作：<code>collect</code>，<code>count</code>，<code>forEach</code></p>

<h1>第五章 Streams 2</h1>

<h2>操作</h2>

<p><strong>Filtering</strong>：<code>filter</code>, <code>distinct</code>, <code>takeWhile</code>(java 9), <code>dropWhile</code>(Java 9), <code>limit</code>, <code>skip</code><br/>
<strong>Mapping</strong>: <code>map</code>, <code>flatMap</code>(入参也是一个stream）<br/>
<strong>Finding</strong>：<code>anyMatch</code>，<code>allMatch</code>，<code>noneMatch</code>，<br/>
               <code>findAny</code>（返回的是Optional，后面接ifPresent），<code>findFirst</code>，<code>findAny</code>和<code>findFirst</code>的功能基本相同，区别在于并行的时候<code>findFirst</code>更加严格<br/>
<strong>Reducing</strong>（Terminal）：<code>reduce(0, Integer::sum)</code>, <code>reduce(Integer::sum</code>）但这个是返回<code>Optional</code>，因为可能stream里面没有元素<br/>
    <code>reduce</code>之前可map成其他数字或对象</p>

<p>Stateful和Stateless的操作，reduce是stateful的操作，但影响并不大。但是sorted，reverse，distinct就是需要空间很大的stateful操作了。</p>

<p>对于<code>IntStream</code>，需要使用boxed让其回到普通stream，或者使用mapToObj，而<code>rangeClose</code>可以构造一个整型int stream出来</p>

<h2>创建streams</h2>

<p><code>Stream.ofNullable(value)</code>，<code>File.lines</code>，<code>Arrays.stream(numbers)</code>，<code>Stream.iterate</code></p>

<h1>第六章 Collectiong 操作（Terminal的一种）</h1>

<p>返回一个值<br/>
返回一群元素<br/>
分区域的一群元素</p>

<pre><code class="java">count() &lt;---&gt; Collectors.counting()  
summingInt, summarizingInt,  
joining()
</code></pre>

<p><code>reducing</code>  --> Collector的reduce，更专业且支持并行操作，reducin接受<T>操作以及&lt;T, T,  T>两种函数接口</p>

<p><code>groupingBy</code>
的第二个参数可以继续传入groupingBy，实际上所有的collector都可以作为第二个参数传入。
默认的groupingBy其实是<code>groupingBy(f, toList())</code></p>

<p><code>collectingAndThen</code>也能传给groupingBy，在有些情况下可以去除里面返回的<code>Optional</code>，<code>maxBy(comparingInt(Dish::getCalories)), Optional::get)));</code>
<code>mapping</code>也经常搭配<code>groupingBy</code>使用，第一个参数是做转换，第二个参数是对转换后的元素做terminal操作。</p>

<p><code>partitioningBy</code>是一种特殊的，只有两个值（true or false）的<code>groupingBy</code></p>

<h2>Collector接口</h2>

<p>接口由4个function+1个特性枚举构成</p>

<p>Collector&lt;T, ?, List<T>> toList() {
        return new CollectorImpl&lt;>(ArrayList::new, List::add,
                                   (left, right) -> { left.addAll(right); return left; },
                                   CH_ID);
    }</p>

<p> static class CollectorImpl&lt;T, A, R> implements Collector&lt;T, A, R> {}</p>

<p>特性枚举：<br/>
1. UNORDERED<br/>
2. CONCURRENT<br/>
3. IDENTITY_FINISH</p>

<p>第2个必须在第1个的基础上才起作用，第三个表明finisher不需要做什么事情</p>

<p>Collector本身也提供了蓝图或者说框架，让开发更简单</p>

<h1>第七章 并行处理</h1>

<p>sequential 和 parallel，但只有最后一个被声明的生效</p>

<p>RecursiveTask<Long>，实现里面的compute() 方法, <code>new ForkJoinPool().invoke(task)</code></p>

<p><code>Spliterator</code>, 并行版的Iterator</p>

<h1>第八章 Collection API 加强</h1>

<p>Java 8:  <code>Arrays.asList</code><br/>
Java 9: <code>List.of</code></p>

<h1>第九章 重构、测试与调试</h1>

<p>lambda在很多情况下可以替换模板方法，以及相当一部分原先需要使用oo来实现的策略模式</p>

<p>多阶函数可以很好的完成职责链的工作，例如<code>thenCombine</code>，<code>thenComparing</code>，<code>and</code>，<code>or</code>等等</p>

<p><code>peek</code>可用于打印stream的内容，调试打印日志时比较有用</p>

<h1>第十章 DSL和lambdas</h1>

<p>用builder模式来实现复杂的构造！！！在builder中实现DSL。</p>

<h1>第十一章 Optional</h1>

<p><code>Optional</code>在定义domain的时候，明显表达了给属性可能为空的事实。<br/>
对于不会为空的字段，则不需要加上Optional。<br/>
用<code>map</code>可以得到里面的值，用<code>flatMap</code>可以脱去可能得到的返回也是<code>Optional</code>的情况</p>

<p>unwrapping的几个方法：<br/>
<code>get()</code>，不值得用，和null检查差不多。<br/>
<code>orElseGet()</code>， lazy 版本，最值得推荐<br/>
<code>orElseThrow()</code></p>

<p><code>map</code>, <code>flatMap</code>其实都是<code>Optional</code>也有的方法，默认返回会携带<code>Optional</code>，用于处理值为空的情况。</p>

<h1>第十二章 New Date and Time Api</h1>

<p>Java老的Date API的问题：<br/>
1. Date的命名不清，月份从0开始，年份从1900开始，没有什么时区的概念<br/>
2. 第二版出了Calendar，年份问题解决，但月份还是从0开始，两个并行带来了困扰<br/>
3. DateFormat不是线程安全的类<br/>
4. Calendar和Date都不是Value Object</p>

<p>新的API主要抄袭了Joda-Time的内容</p>

<p><code>LocalDate</code>，<code>LocalTime</code>，<code>LocalDateTime</code>由前两个组成，甚至localDate和localTime的实例中有<code>createLocalDateTime</code>的工厂方法  <br/>
<code>TemporaField</code>是接口，<code>ChronoField</code>是枚举的实现</p>

<p><code>Instant.now</code></p>

<p><code>Duration</code>用于表示纳秒/毫秒级别的差异，可以用<code>between</code>工厂方法创建<br/>
<code>Period</code> 用于表示天数之间的，可以用于<code>localDate</code>之间的差异<br/>
<code>TemporalAdjusters</code>的静态方法，提供了很多传给<code>with</code>方法以生成新日期对象的调节对象</p>

<p>可以选择实现自己的<code>TemporalAdjuster</code>接口或lambda<br/>
<code>java
 LocalDate date2 = date.with(nextWorkDay());
</code></p>

<p><code>LocalDate.parse</code>可以输入<code>DateTimeFormatter</code>，打印时直接<code>date.format()</code>里面输入需要的formatter</p>

<p><code>ZoneRules</code>，<code>ZoneId</code>，<code>ZoneId</code>混合<code>LocalDateTime</code>等可以新生成`ZonedDateTime</p>

<p><code>ZoneOffset</code>是ZoneId的子类</p>

<h1>第十三章 Default Methods</h1>

<p>为了兼容性，为了可以让API不断演进。</p>

<p>接口可以<code>extends</code>接口，实现多个默认default，会带来多继承的问题。<br/>
解决规则：<strong>Ambiguous的情况下会提示报错</strong>，要求用户再次选择。其他情况下：
1. class里实现的优先级总是高于Interface；
2. 子interface的优先级高于被继承的interface</p>

<p><code>X.super.m(..)</code>的新syntax用于解决Ambiguous的情况。</p>

<p>在子interface中定义一个抽象接口，那么实现该子interface的类就必须实现此方法，尽管在父interface里面可能存在default的实现。</p>

<h1>第十四章 Module</h1>

<p>Java的代码组织层级：1. class 2. package 3. jar，只有class拥有可见性的控制颗粒度，package和jar没有控制</p>

<p>多了require和export用于定义package的开放状态和依赖情况，这些信息位于<code>module-info.java</code>中</p>

<p>java运行时增加了参数 <code>--module-path</code> 可以在后面指定模块对应的jar包</p>

<h1>第十五章 并发（Concurrency）和并行（Parallelism）</h1>

<p>并发是事件类，就是一事未必，再起一事，然后等待几件事情同时得到结果。<br/>
并行是起多个任务同时交给多个core去做。<br/>
GC里也有类似的概念，并发GC意味着GC和应用程序同时进行，并行意味着应用程序暂停但开启多个线程做GC。</p>

<p><code>t1.join()</code>在主线程里面等待t1结束；<br/>
<code>Future&lt;Integer&gt; x</code>, <code>x.get()</code>会blocking等待线程运行结束</p>

<p>Java的新异步方案：<br/>
1. Java 8 中引入的<code>CompletableFuture</code>
2. Java 9 中引入的<code>Flow</code></p>

<p><code>CompletableFutur</code>e同时实现了组合接口，从而拥有了<code>thenCombil</code>e的能力。<code>executorService.submit</code>直接返回的就是<code>Future</code>，但使用<code>CompletableFuture</code>并不用再<code>submit</code>后取得返回，而是自己<code>new</code>了<code>CompletableFuture</code>后使用<code>get</code>。提交时也变成<code>executorService.submit(() -&gt; a.complete(f(x)))</code>;实际往往可以使用工厂方法创建。</p>

<p>订阅模式的pressure和<strong>backpressure</strong>，后者主要用于订阅者确保压力不会太大</p>

<h1>第十六章 CompletableFuture：可组合的异步编程</h1>

<p>主要是为了实现<code>future</code>的组合，其次也是因为Java 8提供了新的机制。Doug Lea大爷出品。</p>

<p><code>CompletableFuture.supplyAsync</code> 工厂方法，入参为Supplier接口，提供一个Callable的返回内容<br/>
所以一般不需要先new一个CompletableFuture再调用complete方法。<br/>
<code>CompletableFuture::join</code>方法可以等待多个join方法执行完成</p>

<pre><code class="java">N(threads) = N(CPU)*U(CPU)*(1+W/C), waitTime/computeTime
</code></pre>

<p><code>.thenApply</code>, <code>.thenCompose</code>，有些结尾如<code>thenComposeAsync</code>，意味着可以不在同一个线程里被执行.<br/>
<code>.thenCombine</code>则是互相不依赖的</p>

<p>Java 9 加入的timeOut特性：orTimeOut（报告异常），completeOnTimeout（添加默认的返回值）</p>

<p>第十七章 Reactive Programming</p>

<p><code>java.util.concurrent.Flow</code>，该接口被众多第三方库实现：<br/>
1. Akka（Lightbend）<br/>
2. Reactor(Pivotal)<br/>
3. RxJava(Netflix)<br/>
4. Vert.x(Red Hat)</p>

<pre><code class="java">public interface Publisher&lt;T&gt; {
    void subscribe(Subscriber&lt;? super T&gt; S);
}
</code></pre>

<pre><code class="java">public interface Subscriber&lt;T&gt; {
    void onSubscribe(Subscription s);
    void onNext(T t);
    void onError(Throwable t);
    void onComplete();  
} 
</code></pre>

<p>onSubscribe onNext* (onError | onComplete)?</p>

<pre><code class="java">public interface Subscription {
    void request(long n);
    void cancel();
}
</code></pre>

<pre><code class="java">public interface Processor&lt;T, R&gt; extends Subscriber&lt;T&gt;, Publisher&lt;R&gt; {}
</code></pre>

<h1>第十八章 函数式考虑</h1>

<p>Tail-recursive的递归可以优化性能，不过java不支持。这种方法的特点是函数的最后就是自己调用自己。</p>

<h1>第十九章 FP技巧</h1>

<p>Higher-order functions：传递函数作为参数的函数<br/>
Curring：可以分批应用参数的函数，其实就是把值先保存在函数体中<br/>
数据结构存储：每次新建一个（批）对象</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apollo Config]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2021/08/19/apollo-config/"/>
    <updated>2021-08-19T17:30:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2021/08/19/apollo-config</id>
    <content type="html"><![CDATA[<p>配置项的管理始终是一个很头疼的问题。虽然磕磕绊绊总能凑合着过，但确实一直不太优雅，甚至容易出错。
人多的情况下，优雅是很难的，还是考虑怎么能减少损耗吧。所以抽空看了看Apollo的东西。</p>

<blockquote><p>Apollo（阿波罗）是携程框架部门研发的开源配置管理中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性。</p></blockquote>

<p>也支持热更新、版本控制、分组等比较实用的特性，据说还能适应复杂的流程治理要求。简单适用了一下，确实不负盛名。</p>

<h3>一. 安装并启动Apollo</h3>

<p>因为是试用，目前使用的是单机版的Apollo，后续可能会进一步调研一下高可用版的发布。</p>

<p>下载 <code>https://github.com/apolloconfig/apollo-build-scripts.git</code> ,  修改<code>demo.sh</code>里面的数据库配置信息和config server信息:</p>

<pre><code> apollo_config_db_url="jdbc:mysql://localhost:3306/ApolloConfigDB?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai"
-apollo_config_db_username=root
-apollo_config_db_password=

 # apollo portal db info
 apollo_portal_db_url="jdbc:mysql://localhost:3306/ApolloPortalDB?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai"
-apollo_portal_db_username=root
-apollo_portal_db_password=

-config_server_url=http://localhost:8080
-admin_server_url=http://localhost:8090
 eureka_service_url=$config_server_url/eureka/
-portal_url=http://localhost:8070
</code></pre>

<p>config server就是未来的meta server，portal就是管理界面。</p>

<h3>二. Java端的配置</h3>

<p>对于基于Sprint Boot的应用而言，最简单和顺利的方式是在bootstrap.yml里面。操作步骤如下</p>

<ol>
<li>加入依赖 <code>   implementation group: 'com.ctrip.framework.apollo', name: 'apollo-client', version: '1.8.0'</code></li>
<li>除去原先对config的依赖 <code>compile('org.springframework.cloud:spring-cloud-starter-config')</code>, 删除整个application.yml文件</li>
<li>删除application.yml文件，并把内容转移到apollo里面</li>
<li>在bootstart.yml里面替换下面的文件</li>
</ol>


<pre><code>apollo:
  bootstrap:
    enabled: true
    namespaces: application,application.yml
  meta: http://xxxx:8080
app:
  id: xxxxxx-compare-monit
</code></pre>

<p>enabled表示启用apollo读取配置，namespaces是给出了需要拉取的namespace，默认只有application一个，如果是自己添加的yml，则需要按上面的配置加一个。
meta就是config server的地址。app.id表示了应用的身份，需要和apollo的对应起来。</p>

<p>如果再portal侧重新发布配置项，可以看见下面的日志</p>

<pre><code>INFO 69947 --- [Apollo-Config-1] c.f.a.s.p.AutoUpdateConfigChangeListener : Auto update apollo changed value successfully, new value: 222222, key: bcmonit.xxxxxKey, beanName: xxxxxxProperties, field: com.xxxxx.address.util.xxxxxProperties.xxxxxKey
</code></pre>

<p>更多的内容可以参考官网的设计文档，对apollo架构的介绍非常到位。</p>

<p><a href="https://www.apolloconfig.com/#/zh/design/apollo-design">Apollo官网设计文档</a></p>

<h3>三. K8S 部署</h3>

<p>首先，要有一个K8S集群，可以参考 https://phoenixnap.com/kb/install-kubernetes-on-ubuntu
来进行操作。但一般会需要trouble shotting，比较好的工具是通过<code>journalctl -xeu kubelet</code> 查看日志来定位问题，然后一一解决</p>

<ul>
<li>安装docker</li>
<li>安装kubeadm kubelet kubectl

<ul>
<li>用apt-mark hold把上面几个组件的版本<strong>定</strong>住</li>
</ul>
</li>
<li>Master

<ul>
<li>用kubeadm init --pod-network-cidr=10.244.0.0/16创建带网络信息的初始化</li>
<li>用kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml部署虚拟网络</li>
<li>查看pods的情况 kubectl get pods --all-namespaces</li>
</ul>
</li>
<li>Workder

<ul>
<li>用kubeadm join --discovery-token abcdef.1234567890abcdef --discovery-token-ca-cert-hash sha256:1234..cdef 1.2.3.4:6443 加入k8s集群。</li>
<li>其中的token可以通过kubeadmin token list查看，通过kubeadmin token create --ttl 0创建，sha256是证书，不会失效</li>
<li>通过kubectl get nodes查看节点状态</li>
</ul>
</li>
<li>安装服务或应用

<ul>
<li>使用helm</li>
<li>使用kubectl apply</li>
</ul>
</li>
</ul>


<p>其次，安装helm，这是一个k8s的包管理工具:</p>

<pre><code>curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -
sudo apt-get install apt-transport-https --yes
echo "deb https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm
</code></pre>

<p>查看安装效果</p>

<p><code>kubectl get pods --all-namespaces -o wide</code> ，这个可以输出实际跑在各节点上的效果</p>

<pre><code>AMESPACE     NAME                                                       READY   STATUS              RESTARTS   AGE     IP             NODE                   NOMINATED NODE   READINESS GATES
default       apollo-service-dev-apollo-adminservice-566996fd98-mkdgm    1/1     Running             0          5d19h   10.244.2.3     master-node            &lt;none&gt;           &lt;none&gt;
default       apollo-service-dev-apollo-configservice-7f955f6f66-x2mjw   0/1     ContainerCreating   0          5d19h   &lt;none&gt;         master-node            &lt;none&gt;           &lt;none&gt;
default       my-nginx-5b56ccd65f-4rngp                                  1/1     Running             0          3h8m    10.244.2.2     master-node            &lt;none&gt;           &lt;none&gt;
kube-system   coredns-78fcd69978-kb5td                                   1/1     Running             0          5d20h   10.244.0.3     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-78fcd69978-l6m5g                                   1/1     Running             0          5d20h   10.244.0.2     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
kube-system   etcd-office-wallet-dev-17                                  1/1     Running             0          5d20h   172.17.3.4     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
kube-system   kube-apiserver-office-wallet-dev-17                        1/1     Running             0          5d20h   172.17.3.4     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
kube-system   kube-controller-manager-office-wallet-dev-17               1/1     Running             0          5d20h   172.17.3.4     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
kube-system   kube-flannel-ds-mbvzp                                      1/1     Running             0          18m     172.17.3.186   master-node            &lt;none&gt;           &lt;none&gt;
kube-system   kube-flannel-ds-x75sk                                      1/1     Running             0          5d20h   172.17.3.4     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-n6q7x                                           1/1     Running             0          18m     172.17.3.186   master-node            &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-ph8s5                                           1/1     Running             0          5d20h   172.17.3.4     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
kube-system   kube-scheduler-office-wallet-dev-17                        1/1     Running             0          5d20h   172.17.3.4     office-wallet-dev-17   &lt;none&gt;           &lt;none&gt;
</code></pre>

<h3>Helm 和 kubectl apply的区别</h3>

<p>默认kube提供的安装服务方法是<code>kubectl apply -f ./run-my-nginx.yaml</code>，适用于应用比较少的情况。如果应用很多，那么helm就可以帮上忙了。</p>

<p>https://www.apolloconfig.com/#/zh/deployment/distributed-deployment-guide?id=_24-kubernetes%e9%83%a8%e7%bd%b2</p>

<p>groovy for gradle:</p>

<p>https://docs.gradle.org/current/dsl/org.gradle.api.Task.html</p>

<p>https://docs.gradle.org/current/userguide/tutorial_using_tasks.html</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mysql的库表容量查询]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2021/08/09/mysqlde-ku-biao-rong-liang-cha-xun/"/>
    <updated>2021-08-09T17:52:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2021/08/09/mysqlde-ku-biao-rong-liang-cha-xun</id>
    <content type="html"><![CDATA[<pre><code>select  
table_schema as '数据库',  
table_name as '表名',  
table_rows as '记录数',  
truncate(data_length/1024/1024, 2) as '数据容量(MB)',  
truncate(index_length/1024/1024, 2) as '索引容量(MB)'  
from information_schema.tables  
order by data_length desc, index_length desc; 
</code></pre>

<p>可以查询库里的表名、数据容量和索引容量。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CORS问题]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2021/03/18/corswen-ti/"/>
    <updated>2021-03-18T13:40:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2021/03/18/corswen-ti</id>
    <content type="html"><![CDATA[<p>动手搞了一下Nginx和Chrome的CORS问题，顺手记录一下一些基本概念。</p>

<p>CORS的本意是限制Http请求中Origin的来源，主要是用于保护浏览器客户端的，可以一定程度上防止浏览器访问页面A时，莫名其妙连去B站资源的情况发生。</p>

<p>原理上，CORS工作时会先发出一个OPTIONS请求，并携带Origin消息头：</p>

<pre><code>OPTIONS /
Host: service.example.com
Origin: http://www.example.com
Access-Control-Request-Method: PUT
</code></pre>

<p>然后，服务器端如果支持跨域，则会返回Access-Control-Allow-Origin消息头，里面给出允许访问的Origin域名。如果用<code>*</code>，则表示没有任何限制。如果要允许多个域名，则可以使用Nginx中动态变量的方法，这种情况下每次还是只返回一个域名。</p>

<pre><code>location / {

                root html;
             if ($request_method = "OPTIONS") {
add_header Access-Control-Allow-Origin *;
                add_header 'Access-Control-Allow-Credentials' 'true';
                add_header 'Access-Control-Allow-Headers' 'Authorization,Content-Type,Accept,Origin,User-Agent,DNT,Cache-Control,X-Mx-ReqToken,X-Requested-With';
                add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';
                add_header 'Access-Control-Max-Age' 10;
                return 204;
             }

                add_header 'Access-Control-Allow-Credentials' 'true' always;
                add_header 'Access-Control-Allow-Headers' 'Authorization,Content-Type,Accept,Origin,User-Agent,DNT,Cache-Control,X-Mx-ReqToken,X-Requested-With' always;
                add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS' always;
                add_header 'Access-Control-Max-Age' 10 always;
                proxy_set_header host $host;
                proxy_set_header X-real-ip $remote_addr;
                proxy_set_header X-forward-for $proxy_add_x_forwarded_for;
                proxy_pass http://127.0.0.1:8080;
        }
</code></pre>

<p>Nginx的配置需要注意两点：</p>

<ol>
<li>add_header在proxy_pass时默认不会起作用，如果需要起作用，则要加上<code>always</code>参数。</li>
<li>Access-Control-Allow-Origin 要严格的只有1条，不能有多条。</li>
</ol>

]]></content>
  </entry>
  
</feed>
